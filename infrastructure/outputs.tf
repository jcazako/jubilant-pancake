# Output values for LLM Inference Service
